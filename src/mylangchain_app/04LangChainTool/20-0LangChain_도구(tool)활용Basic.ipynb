{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. LangChain에서 도구(tool) 활용 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs\n",
      "z6\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "print(OPENAI_API_KEY[:2])\n",
    "\n",
    "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
    "print(UPSTAGE_API_KEY[30:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\pypoetry\\Cache\\virtualenvs\\mylangchain-app-SBe-Yh6W-py3.12\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.completions.Completions object at 0x000002B14FDBC200> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B14FE29550> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n"
     ]
    }
   ],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# llm = ChatOpenAI(\n",
    "#     base_url=\"https://api.groq.com/openai/v1\",\n",
    "#     #model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "#     model=\"moonshotai/kimi-k2-instruct-0905\",\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "from langchain_upstage import ChatUpstage\n",
    "llm = ChatUpstage(\n",
    "        model=\"solar-pro\",\n",
    "        base_url=\"https://api.upstage.ai/v1\",\n",
    "        temperature=0.5\n",
    "    )\n",
    "print(llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [tool decorator](https://python.langchain.com/docs/how_to/custom_tools/#tool-decorator)를 사용하면 쉽게 도구를 만들 수 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 더합니다.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"숫자 a와 b를 곱합니다.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool 데코레이터로 선언된 함수는 직접 호출할 수 없다.\n",
    "# add(10,20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LLM을 호출했을 때와 도구를 사용했을 때의 차이를 알아봅니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_reuslt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m query = \u001b[33m'\u001b[39m\u001b[33m3 곱하기 5는?\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m      2\u001b[39m llm_result = llm.invoke(query)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mllm_reuslt\u001b[49m.content)\n",
      "\u001b[31mNameError\u001b[39m: name 'llm_reuslt' is not defined"
     ]
    }
   ],
   "source": [
    "query = '3 곱하기 5는?'\n",
    "llm_result = llm.invoke(query)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도구 리스트는 LLM에 해당하는 `BaseModel` 클래스에 `bind_tools` 메서드를 통해 전달합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.runnables.base.RunnableBinding'>\n",
      "bound=ChatUpstage(client=<openai.resources.chat.completions.completions.Completions object at 0x000002B14FDBC200>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002B14FE29550>, model_name='solar-pro', temperature=0.5, model_kwargs={}, upstage_api_key=SecretStr('**********'), upstage_api_base='https://api.upstage.ai/v1') kwargs={'tools': [{'type': 'function', 'function': {'name': 'add', 'description': '숫자 a와 b를 더합니다.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}, {'type': 'function', 'function': {'name': 'multiply', 'description': '숫자 a와 b를 곱합니다.', 'parameters': {'properties': {'a': {'type': 'integer'}, 'b': {'type': 'integer'}}, 'required': ['a', 'b'], 'type': 'object'}}}]} config={} config_factories=[]\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools([add, multiply])\n",
    "\n",
    "print(type(llm_with_tools))\n",
    "print(llm_with_tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AIMessage`의 `additional_kwargs` 속성은 `tool_calls`를 포함합니다\n",
    "- `tool_calls`는 도구를 호출하는 메시지를 포함합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[질문 \"3 곱하기 5는?\"을 해결하기 위해 곱셈 연산이 필수적이며, `multiply` 함수가 직접 필요한 계산을 수행하므로 호출합니다.]  \\n\\n결과: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-a4b5ec44f7fe4426a909aff8d75fd16b', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 578, 'total_tokens': 634, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '241af6de-6f73-49fe-98d0-f6b99c214266', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--c3d8c16b-a319-4c2e-b92e-93e5bf04ef0e-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-a4b5ec44f7fe4426a909aff8d75fd16b', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 56, 'total_tokens': 634, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_result = llm_with_tools.invoke(query)\n",
    "\n",
    "tool_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 3, 'b': 5},\n",
       "  'id': 'chatcmpl-tool-a4b5ec44f7fe4426a909aff8d75fd16b',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "from langchain_core.messages import AnyMessage, HumanMessage\n",
    "\n",
    "query=\"20과 10을 더하고 곱한 결과\"\n",
    "human_message = HumanMessage(query)\n",
    "message_list: Sequence[AnyMessage] = [human_message] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tool_calls` 속성은 도구를 호출하는 메시지를 포함합니다\n",
    "- `tool_calls`를 가진 `AIMessage`의 형태를 기억하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='[질문에서 \"20과 10을 더하고 곱한 결과\"를 요구하므로, 덧셈(add)과 곱셈(multiply) 연산이 모두 필수적입니다. 두 함수 호출은 각각 필요한 계산을 수행하기 위해 선택되었습니다.]  \\n\\n결과:  \\n- 덧셈: 20 + 10 = **30**  \\n- 곱셈: 20 × 10 = **200**', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53', 'function': {'arguments': '{\"a\": 20, \"b\": 10}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba', 'function': {'arguments': '{\"a\": 20, \"b\": 10}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 582, 'total_tokens': 693, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '8c9080b2-7c47-4771-918a-1f4286f5bca2', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--60254aaf-723c-4b26-bcf2-efed63e2817f-0', tool_calls=[{'name': 'add', 'args': {'a': 20, 'b': 10}, 'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 20, 'b': 10}, 'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba', 'type': 'tool_call'}], usage_metadata={'input_tokens': 582, 'output_tokens': 111, 'total_tokens': 693, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message = llm_with_tools.invoke(message_list)\n",
    "ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 20, 'b': 10},\n",
       "  'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 20, 'b': 10},\n",
       "  'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='20과 10을 더하고 곱한 결과', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[질문에서 \"20과 10을 더하고 곱한 결과\"를 요구하므로, 덧셈(add)과 곱셈(multiply) 연산이 모두 필수적입니다. 두 함수 호출은 각각 필요한 계산을 수행하기 위해 선택되었습니다.]  \\n\\n결과:  \\n- 덧셈: 20 + 10 = **30**  \\n- 곱셈: 20 × 10 = **200**', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53', 'function': {'arguments': '{\"a\": 20, \"b\": 10}', 'name': 'add'}, 'type': 'function'}, {'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba', 'function': {'arguments': '{\"a\": 20, \"b\": 10}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 582, 'total_tokens': 693, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '8c9080b2-7c47-4771-918a-1f4286f5bca2', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--60254aaf-723c-4b26-bcf2-efed63e2817f-0', tool_calls=[{'name': 'add', 'args': {'a': 20, 'b': 10}, 'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 20, 'b': 10}, 'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba', 'type': 'tool_call'}], usage_metadata={'input_tokens': 582, 'output_tokens': 111, 'total_tokens': 693, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "message_list.append(ai_message)\n",
    "\n",
    "pprint(message_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `AIMessage`의 `tool_calls`를 활용해서 도구를 직접 호출할 수도 있습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 20, 'b': 10},\n",
       "  'id': 'chatcmpl-tool-fb98cee10885441db7be0f6950d66c53',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 20, 'b': 10},\n",
       "  'id': 'chatcmpl-tool-3a43f29e9ad5498ea3ad64dd587cfbba',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='15' name='multiply' tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5'\n"
     ]
    }
   ],
   "source": [
    "tool_message = multiply.invoke(ai_message.tool_calls[0])\n",
    "\n",
    "print(tool_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 하지만 에이전트의 경우 도구를 직접 호출하는 것이 아니라 도구를 호출하는 메시지를 만들어서 전달합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessage(content='3 곱하기 5는?', additional_kwargs={}, response_metadata={}),\n",
      " AIMessage(content='[주어진 질문은 \"3 곱하기 5\"의 결과를 묻는 것으로, 이는 직접적으로 곱셈 연산이 필요합니다. 따라서 \\'multiply\\' 함수를 호출하는 것이 필수적입니다. 다른 방법으로는 일반 지식으로도 답할 수 있지만, 규칙에 따라 함수 사용이 필요한 경우에만 호출해야 하며, 이 경우 곱셈 연산이 질문의 핵심이므로 함수 호출이 정당합니다.] \\n\\n정답: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
      " ToolMessage(content='15', name='multiply', tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5')]\n"
     ]
    }
   ],
   "source": [
    "message_list.append(tool_message)\n",
    "\n",
    "pprint(message_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIMessage(content='3 곱하기 5는 15입니다. \\n\\n함수 호출 결과와 일치하는 정답을 확인했습니다.\\n\\n[질문의 핵심인 \"3 곱하기 5\" 연산을 수행하기 위해 \\'multiply\\' 함수가 필수적으로 요구됩니다. 일반 지식으로도 답변 가능하지만, 문제 해결을 위해 함수 사용이 명시적으로 요청된 상황으로 판단됩니다.] \\n\\n최종 답변: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-99c188eebb814a838f6526d0c3606084', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 682, 'total_tokens': 768, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '37df693b-c96e-440c-8257-b928d4e05a01', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--bb7bb29f-23f3-4d89-aecd-5884b8a4ccb9-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-99c188eebb814a838f6526d0c3606084', 'type': 'tool_call'}], usage_metadata={'input_tokens': 682, 'output_tokens': 86, 'total_tokens': 768, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})\n"
     ]
    }
   ],
   "source": [
    "tool_result = llm_with_tools.invoke(message_list)\n",
    "\n",
    "pprint(tool_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `message_list`의 순서를 기억하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='3 곱하기 5는?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='[주어진 질문은 \"3 곱하기 5\"의 결과를 묻는 것으로, 이는 직접적으로 곱셈 연산이 필요합니다. 따라서 \\'multiply\\' 함수를 호출하는 것이 필수적입니다. 다른 방법으로는 일반 지식으로도 답할 수 있지만, 규칙에 따라 함수 사용이 필요한 경우에만 호출해야 하며, 이 경우 곱셈 연산이 질문의 핵심이므로 함수 호출이 정당합니다.] \\n\\n정답: 15', additional_kwargs={'tool_calls': [{'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'function': {'arguments': '{\"a\": 3, \"b\": 5}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 89, 'prompt_tokens': 578, 'total_tokens': 667, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '11c36d9a-83e6-406f-b0a9-0ee6e9525b33', 'service_tier': None, 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--1e6c9b67-caf5-4549-aac5-abddf1b12069-0', tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 5}, 'id': 'chatcmpl-tool-638066a86a0143c682396fe4fde379e5', 'type': 'tool_call'}], usage_metadata={'input_tokens': 578, 'output_tokens': 89, 'total_tokens': 667, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}),\n",
       " ToolMessage(content='15', name='multiply', tool_call_id='chatcmpl-tool-638066a86a0143c682396fe4fde379e5')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
