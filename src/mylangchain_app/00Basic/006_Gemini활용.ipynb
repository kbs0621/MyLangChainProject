{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0fa4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -q langchain-google-genai\n",
    "# poetry add langchain-google-genai\n",
    "# poetry show langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8264ea0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIza\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "# .env 파일을 불러와서 환경 변수로 설정\n",
    "load_dotenv(dotenv_path='../.env')\n",
    "\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "print(GOOGLE_API_KEY[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d93f00ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Google Gemini Response:\n",
      "LangChain은 대규모 언어 모델(LLM)을 애플리케이션에 통합하기 위한 프레임워크입니다.  단순히 LLM을 호출하는 것을 넘어, 여러 LLM을 연결하고, 외부 데이터 소스와 상호 작용하며, 메모리 및 채팅 기능을 제공하여 더욱 강력하고 유용한 애플리케이션을 구축할 수 있도록 지원합니다.  핵심 기능은 다음과 같습니다.\n",
      "\n",
      "* **모듈화:** LangChain은 다양한 구성 요소(LLM, 프로세서, 메모리, 데이터 연결 등)를 모듈화하여 재사용성과 유연성을 높입니다.  다양한 LLM(OpenAI, Hugging Face 등)과 데이터 소스를 쉽게 교체하고 통합할 수 있습니다.\n",
      "\n",
      "* **체인(Chains):**  여러 구성 요소를 순차적으로 또는 병렬적으로 연결하여 복잡한 작업을 수행할 수 있습니다. 예를 들어, 문서를 요약하고, 요약된 내용을 기반으로 질문에 답하는 체인을 만들 수 있습니다.\n",
      "\n",
      "* **인덱싱 및 검색:**  외부 데이터 소스(문서, 데이터베이스 등)를 인덱싱하고 검색하여 LLM이 외부 정보를 활용할 수 있도록 합니다.  이를 통해 LLM의 지식 범위를 확장하고, 최신 정보를 활용한 응답을 생성할 수 있습니다.\n",
      "\n",
      "* **메모리:**  이전 상호 작용의 내용을 기억하여 맥락을 유지하고 일관성 있는 대화를 가능하게 합니다.  다양한 메모리 유형(단기 메모리, 장기 메모리 등)을 제공하여 애플리케이션의 요구사항에 맞게 선택할 수 있습니다.\n",
      "\n",
      "* **에이전트(Agents):**  LLM이 외부 도구(검색 엔진, 계산기 등)를 사용하여 작업을 수행할 수 있도록 합니다.  에이전트는 LLM이 어떤 도구를 사용할지 결정하고, 도구의 결과를 활용하여 최종 응답을 생성합니다.\n",
      "\n",
      "* **다양한 LLM 지원:**  OpenAI, Hugging Face Hub, Google AI Platform 등 다양한 LLM 및 모델을 지원합니다.\n",
      "\n",
      "**LangChain의 장점:**\n",
      "\n",
      "* **개발 속도 향상:**  모듈화된 구성 요소와 다양한 기능을 통해 애플리케이션 개발 시간을 단축할 수 있습니다.\n",
      "* **유연성:**  다양한 LLM, 데이터 소스, 구성 요소를 쉽게 통합할 수 있습니다.\n",
      "* **확장성:**  복잡한 애플리케이션을 구축하고 확장하기 용이합니다.\n",
      "* **재사용성:**  구축된 구성 요소와 체인을 다른 애플리케이션에 재사용할 수 있습니다.\n",
      "\n",
      "\n",
      "**LangChain의 단점:**\n",
      "\n",
      "* **복잡성:**  다양한 기능과 구성 요소로 인해 초보자에게는 다소 복잡하게 느껴질 수 있습니다.\n",
      "* **학습 곡선:**  LangChain을 효과적으로 사용하려면 특정 수준의 프로그래밍 지식이 필요합니다.\n",
      "* **의존성:**  LangChain은 다른 라이브러리에 의존하므로, 환경 설정에 어려움을 겪을 수 있습니다.\n",
      "\n",
      "\n",
      "결론적으로, LangChain은 LLM 기반 애플리케이션 개발을 위한 강력하고 유연한 프레임워크입니다.  복잡한 애플리케이션을 구축하고자 하는 개발자에게 유용한 도구이지만,  초보자는 학습 곡선을 고려해야 합니다.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "    \n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 모델 초기화\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",  # 또는 \"gemini-pro-vision\"\n",
    "    temperature=0.3    \n",
    ")\n",
    "\n",
    "# 프롬프트 설정\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 AI 전문가입니다.\"),\n",
    "    (\"human\", \"{topic}은 무엇인가요?\")\n",
    "])\n",
    "\n",
    "# 체인 실행\n",
    "chain = prompt | llm\n",
    "response = chain.invoke({\"topic\": \"LangChain\"})\n",
    "\n",
    "print(\" Google Gemini Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99bcfff",
   "metadata": {},
   "source": [
    "#### Gemini 모델별 특징\n",
    "\n",
    "* gemini-1.5-flash: 빠른 응답, 일반적인 작업에 적합\n",
    "* gemini-1.5-pro: 더 정확하고 복잡한 추론 작업\n",
    "* gemini-pro-vision: 이미지 처리 및 멀티모달 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37613cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "예제 1: 기본 대화형 챗봇\n",
      "==================================================\n",
      "응답: 파이썬에서 리스트를 정렬하는 방법은 여러 가지가 있습니다.  어떤 방법을 사용할지는 리스트의 데이터 타입과 정렬 기준에 따라 달라집니다.  자세히 알아보겠습니다.\n",
      "\n",
      "**1. `list.sort()` 메서드:**\n",
      "\n",
      "* 리스트 자체를 직접 정렬합니다.  즉, 원본 리스트를 변경합니다.  새로운 리스트를 반환하지 않습니다.\n",
      "* `in-place` 정렬이라고 하며, 일반적으로 `list.sort()`가 `sorted()` 함수보다 효율적입니다.  특히 큰 리스트를 다룰 때 성능 차이가 큽니다.\n",
      "* 기본적으로 오름차순으로 정렬합니다.  내림차순으로 정렬하려면 `reverse=True` 인수를 사용합니다.\n",
      "* 키(key) 인수를 사용하여 정렬 기준을 지정할 수 있습니다.  예를 들어, 문자열 리스트를 길이 순으로 정렬하거나, 객체 리스트를 특정 속성 순으로 정렬할 수 있습니다.\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬 (원본 리스트 변경)\n",
      "my_list.sort()\n",
      "print(f\"오름차순 정렬: {my_list}\")  # 출력: 오름차순 정렬: [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "\n",
      "# 내림차순 정렬 (원본 리스트 변경)\n",
      "my_list.sort(reverse=True)\n",
      "print(f\"내림차순 정렬: {my_list}\")  # 출력: 내림차순 정렬: [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "\n",
      "\n",
      "words = [\"banana\", \"apple\", \"cherry\", \"date\"]\n",
      "\n",
      "# 길이 순으로 오름차순 정렬\n",
      "words.sort(key=len)\n",
      "print(f\"길이 순으로 정렬: {words}\")  # 출력: 길이 순으로 정렬: ['date', 'apple', 'banana', 'cherry']\n",
      "\n",
      "\n",
      "class Person:\n",
      "    def __init__(self, name, age):\n",
      "        self.name = name\n",
      "        self.age = age\n",
      "\n",
      "people = [Person(\"Alice\", 30), Person(\"Bob\", 25), Person(\"Charlie\", 35)]\n",
      "\n",
      "# 나이 순으로 오름차순 정렬\n",
      "people.sort(key=lambda person: person.age)\n",
      "print(f\"나이 순으로 정렬: {[person.name for person in people]}\") # 출력: 나이 순으로 정렬: ['Bob', 'Alice', 'Charlie']\n",
      "\n",
      "```\n",
      "\n",
      "**2. `sorted()` 함수:**\n",
      "\n",
      "* 새로운 정렬된 리스트를 반환합니다.  원본 리스트는 변경되지 않습니다.\n",
      "* `list.sort()` 메서드와 마찬가지로 `reverse`와 `key` 인수를 사용할 수 있습니다.\n",
      "\n",
      "\n",
      "```python\n",
      "my_list = [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "# 오름차순 정렬 (새로운 리스트 반환)\n",
      "sorted_list = sorted(my_list)\n",
      "print(f\"오름차순 정렬: {sorted_list}\")  # 출력: 오름차순 정렬: [1, 1, 2, 3, 4, 5, 6, 9]\n",
      "print(f\"원본 리스트: {my_list}\")  # 출력: 원본 리스트: [3, 1, 4, 1, 5, 9, 2, 6]\n",
      "\n",
      "\n",
      "# 내림차순 정렬 (새로운 리스트 반환)\n",
      "sorted_list = sorted(my_list, reverse=True)\n",
      "print(f\"내림차순 정렬: {sorted_list}\")  # 출력: 내림차순 정렬: [9, 6, 5, 4, 3, 2, 1, 1]\n",
      "```\n",
      "\n",
      "\n",
      "어떤 방법을 선택할지는 상황에 따라 다릅니다.  원본 리스트를 변경하지 않고 정렬된 새로운 리스트를 얻어야 한다면 `sorted()` 함수를 사용하고,  메모리를 절약하고 원본 리스트를 직접 변경하는 것이 허용된다면 `list.sort()` 메서드를 사용하는 것이 더 효율적입니다.  `key` 인수를 활용하면 다양한 기준으로 정렬할 수 있으니 필요에 따라 적절히 사용하세요.\n",
      "\n",
      "==================================================\n",
      "예제 2: JSON 구조화 출력\n",
      "==================================================\n",
      "JSON 결과: ```json\n",
      "{\"name\": \"네이버\", \"year\": \"1999\", \"location\": \"경기도 성남\"}\n",
      "```\n",
      "\n",
      "==================================================\n",
      "예제 3: 번역 체인\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# API 키 설정\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = \"your-google-api-key\"\n",
    "\n",
    "# 기본 모델 설정\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"예제 1: 기본 대화형 챗봇\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 대화형 프롬프트\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"당신은 친근하고 도움이 되는 AI 어시스턴트입니다.\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "chat_chain = chat_prompt | llm | StrOutputParser()\n",
    "response1 = chat_chain.invoke({\"user_input\": \"파이썬으로 리스트를 정렬하는 방법은?\"})\n",
    "print(\"응답:\", response1)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 2: JSON 구조화 출력\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "json_prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "다음 정보를 JSON 형태로 변환하세요:\n",
    "{company_info}\n",
    "\n",
    "형식: {{\"name\": \"회사명\", \"year\": \"연도\", \"location\": \"위치\"}}\n",
    "\"\"\",\n",
    "    input_variables=[\"company_info\"]\n",
    ")\n",
    "\n",
    "json_chain = json_prompt | llm | StrOutputParser()\n",
    "company_text = \"네이버는 1999년에 설립된 한국의 IT 기업이며 본사는 경기도 성남에 있습니다.\"\n",
    "response2 = json_chain.invoke({\"company_info\": company_text})\n",
    "print(\"JSON 결과:\", response2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 3: 번역 체인\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2331af30",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "translate_prompt = ChatPromptTemplate.from_template(\n",
    "    \"다음 텍스트를 {target_language}로 번역하세요: {text}\"\n",
    ")\n",
    "\n",
    "translate_chain = translate_prompt | llm | StrOutputParser()\n",
    "original = \"Hello, how are you today?\"\n",
    "translated = translate_chain.invoke({\n",
    "    \"text\": original, \n",
    "    \"target_language\": \"한국어\"\n",
    "})\n",
    "print(\"번역 결과:\", translated)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 4: 감정 분석\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "emotion_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "텍스트: {text}\n",
    "감정을 분석하고 [긍정/부정/중립]과 1-10점수를 매기세요.\n",
    "\"\"\")\n",
    "\n",
    "emotion_chain = emotion_prompt | llm | StrOutputParser()\n",
    "test_text = \"오늘 프로젝트가 성공적으로 완료되어서 정말 기쁩니다!\"\n",
    "emotion_result = emotion_chain.invoke({\"text\": test_text})\n",
    "print(\"감정 분석:\", emotion_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 5: 코드 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "code_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "{language}로 {task} 기능을 구현하는 간단한 코드를 작성하세요.\n",
    "\"\"\")\n",
    "\n",
    "code_chain = code_prompt | llm | StrOutputParser()\n",
    "code_result = code_chain.invoke({\n",
    "    \"language\": \"Python\",\n",
    "    \"task\": \"두 숫자의 최대공약수를 구하는\"\n",
    "})\n",
    "print(\"생성된 코드:\")\n",
    "print(code_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"예제 6: 창의적 콘텐츠 생성\")\n",
    "print(\"=\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001da18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 창의적 생성용 높은 temperature\n",
    "llm_creative = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-1.5-flash\",\n",
    "    temperature=0.9\n",
    ")\n",
    "\n",
    "creative_prompt = ChatPromptTemplate.from_template(\n",
    "    \"{topic}에 대한 창의적인 {content_type}를 {style} 스타일로 작성하세요.\"\n",
    ")\n",
    "\n",
    "creative_chain = creative_prompt | llm_creative | StrOutputParser()\n",
    "creative_result = creative_chain.invoke({\n",
    "    \"topic\": \"미래의 교통수단\",\n",
    "    \"content_type\": \"아이디어\",\n",
    "    \"style\": \"혁신적이고 실현 가능한\"\n",
    "})\n",
    "print(\"창의적 아이디어:\", creative_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"Gemini 모델 옵션\")\n",
    "print(\"=\" * 50)\n",
    "print(\"• gemini-1.5-flash: 빠른 응답, 일반 작업\")\n",
    "print(\"• gemini-1.5-pro: 정확한 분석, 복잡한 추론\")\n",
    "print(\"• gemini-pro-vision: 이미지 처리 가능\")\n",
    "print(\"• temperature: 0.1(정확) ~ 0.9(창의적)\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
