{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangChain vs LangGraph (feat. LangGraph 개념 설명)\n",
        "* LangGraph의 개념과 주요 기능을 이해하고, 차이점을 비교합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [],
      "source": [
        "# poetry add langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sk\n",
            "z6\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "print(OPENAI_API_KEY[:2])\n",
        "\n",
        "UPSTAGE_API_KEY = os.getenv(\"UPSTAGE_API_KEY\")\n",
        "print(UPSTAGE_API_KEY[30:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "client=<openai.resources.chat.completions.completions.Completions object at 0x000002A90D3EB650> async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000002A90D3E8BC0> model_name='solar-pro' temperature=0.5 model_kwargs={} upstage_api_key=SecretStr('**********') upstage_api_base='https://api.upstage.ai/v1'\n",
            "**LangGraph**는 **Language Model(LM)과 그래프 기반 상태 관리를 결합한 프레임워크**로, 복잡한 멀티턴 대화나 상태 유지가 필요한 애플리케이션(예: 챗봇, 워크플로우 자동화, 게임 대화 시스템)을 구축하기 위해 설계되었습니다.  \n",
            "\n",
            "### 주요 특징:\n",
            "1. **그래프 기반 상태 관리**  \n",
            "   - 대화를 **노드(Node)**와 **엣지(Edge)**로 구성된 그래프로 표현합니다.  \n",
            "     - **노드**: 특정 상태(예: \"사용자 인증 완료\", \"주문 확인 중\")를 나타냅니다.  \n",
            "     - **엣지**: 상태 전이 조건(예: \"예\" 입력 시 다음 단계로 이동)을 정의합니다.  \n",
            "   - LLM의 출력을 기반으로 동적으로 경로를 선택할 수 있습니다.\n",
            "\n",
            "2. **LLM과의 통합**  \n",
            "   - LangChain, LLaMA, GPT 등 다양한 언어 모델과 연동 가능합니다.  \n",
            "   - 사용자 입력을 LLM이 처리하고, 그래프 엔진이 상태를 추적하며 흐름을 제어합니다.\n",
            "\n",
            "3. **확장성**  \n",
            "   - 커스텀 노드/엣지를 추가해 복잡한 워크플로우(예: 결제 프로세스, 고객 지원 티켓 시스템)를 구축할 수 있습니다.  \n",
            "   - 메모리 관리, 도구 호출(예: 외부 API 연동) 등의 기능을 지원합니다.\n",
            "\n",
            "4. **사용 사례**  \n",
            "   - **대화형 에이전트**: 사용자 질문에 따라 동적으로 응답하는 챗봇.  \n",
            "   - **워크플로우 자동화**: 다단계 프로세스(예: 대출 신청 절차)를 그래프로 관리.  \n",
            "   - **게임 AI**: 플레이어 선택에 따라 분기되는 대화 시스템.\n",
            "\n",
            "### 예시:\n",
            "```python\n",
            "from langgraph import State, Graph\n",
            "\n",
            "# 상태 정의\n",
            "class MyState(State):\n",
            "    user_input: str\n",
            "    step: str\n",
            "\n",
            "# 그래프 생성\n",
            "with Graph(MyState) as graph:\n",
            "    # 노드 정의 (예: \"시작\", \"인증\", \"완료\")\n",
            "    start = (\n",
            "        lambda state: {\"step\": \"인증 필요\"},\n",
            "        cond=lambda state: state.step == \"인증 필요\",\n",
            "    )\n",
            "    auth = (\n",
            "        lambda state: {\"step\": \"완료\"},\n",
            "        cond=lambda state: state.step == \"인증 필요\",\n",
            "    )\n",
            "    end = lambda state: {\"done\": True}\n",
            "\n",
            "# 실행\n",
            "state = MyState(user_input=\"인증해 주세요\")\n",
            "for event in graph.stream(state):\n",
            "    print(event)\n",
            "```\n",
            "\n",
            "### 관련 기술:\n",
            "- **LangChain**: LLM 기반 애플리케이션 구축을 위한 라이브러리. LangGraph는 LangChain의 확장으로 볼 수 있습니다.  \n",
            "- **Stateful Agents**: 장기적인 대화 컨텍스트를 유지하는 에이전트.  \n",
            "\n",
            "LangGraph는 **복잡한 대화 흐름을 시각화/관리**할 수 있어, 개발자 친화적인 도구로 주목받고 있습니다. 공식 문서나 GitHub 저장소에서 더 자세한 예제를 확인할 수 있습니다.\n"
          ]
        }
      ],
      "source": [
        "# from langchain_openai import ChatOpenAI\n",
        "\n",
        "# llm = ChatOpenAI(model='gpt-4o-mini') # 테스트의 경우에는 작은 모델을 사용합니다\n",
        "\n",
        "from langchain_upstage import ChatUpstage\n",
        "llm = ChatUpstage(\n",
        "        model=\"solar-pro\",\n",
        "        base_url=\"https://api.upstage.ai/v1\",\n",
        "        temperature=0.5\n",
        "    )\n",
        "print(llm)\n",
        "\n",
        "query = 'LangGraph는 무엇인가요?'\n",
        "ai_msg = llm.invoke(query)\n",
        "print(ai_msg.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### LangGraph의 기본개념\n",
        "* `state`는 LangGraph 에이전트의 state를 나타내는 데이터 구조입니다.\n",
        "* `state`는 `TypedDict`를 사용하여 정의되며, 이는 Python의 타입 힌팅을 통해 구조를 명확히 합니다.\n",
        "    * 간단하게 `messages`라는 필드만 있습니다.\n",
        "    * 필요에 따라 다양한 값들을 활용할 수 있습니다.\n",
        "* `state`는 에이전트의 동작을 결정하는 데 사용되며, 각 노드에서 state를 업데이트하거나 참조할 수 있습니다.\n",
        "* `state`는 LangGraph의 노드 간에 전달되며, 에이전트의 state 전이를 관리합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "from typing import Annotated # 타입 힌트를 사용하기 위해 \n",
        "from typing_extensions import TypedDict # 구조화된 딕셔너리 타입을 정의하기 위해 \n",
        "\n",
        "from langgraph.graph.message import add_messages \n",
        "from langchain_core.messages import AnyMessage # LangChain에서 사용하는 모든 종류의 메시지(예: HumanMessage, AIMessage, ToolMessage)\n",
        "\n",
        "# AgentState는 에이전트의 현재 상태를 나타내는 딕셔너리 타입을 정의합니다.\n",
        "# TypedDict를 사용하면 딕셔너리가 어떤 키와 값 타입을 가져야 하는지 명확하게 지정할 수 있습니다.\n",
        "class AgentState(TypedDict):\n",
        "    # 'messages' 키는 에이전트의 대화 기록을 저장합니다.\n",
        "    # 이 목록에는 LangChain 메시지 객체(AnyMessage)가 들어갑니다.\n",
        "    # LangGraph가 이 상태를 처리할 때, 새로운 메시지가 추가되면\n",
        "    # 기존 메시지 목록의 끝에 자동으로 추가되도록(append) 설정합니다.\n",
        "    messages: list[Annotated[AnyMessage, add_messages]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 위에 선언한 `AgentState`를 활용하여 `StateGraph`를 생성합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.StateGraph'>\n"
          ]
        }
      ],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "graph_builder = StateGraph(AgentState)\n",
        "print(type(graph_builder))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `graph`에 추가할 `node`를 생성합니다\n",
        "-  `node`는 LangGraph에서 실행되는 개별적인 작업 단위를 의미합니다. \n",
        "    - 각 노드는 특정 기능을 수행하는 독립적인 컴포넌트로, 예를 들어 텍스트 생성, 데이터 처리, 또는 의사 결정과 같은 작업을 담당할 수 있습니다.\n",
        "    - `node`는 기본적으로 함수(function)로 정의되고, 뒤에서 다루지만 다른 에이전트(agent)를 활용할 수도 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Node 역할을 하는 함수의 인자로 state 객체를 사용함  LLM을 호출하는 노드\n",
        "def generate(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    `generate` 노드는 사용자의 질문을 받아서 응답을 생성하는 노드입니다.\n",
        "    \"\"\"\n",
        "    messages = state['messages']\n",
        "    ai_message = llm.invoke(messages)\n",
        "    return {'messages': [ai_message]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`를 생성한 후에 `edge`로 연결합니다\n",
        "- `edge`는 노드들 사이의 연결을 나타내며, 데이터와 제어 흐름의 경로를 정의합니다. \n",
        "    - 엣지를 통해 한 노드의 출력이 다음 노드의 입력으로 전달되어, 전체적인 워크플로우가 형성됩니다.\n",
        "    - `node`와 `edge`의 조합은 방향성 그래프(Directed Graph)를 형성하며, 이를 통해 복잡한 AI 에이전트의 행동 흐름을 구조화할 수 있습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2a90d3eadb0>"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# LLM을 호출하는 generate 함수를 Node로 추가함\n",
        "graph_builder.add_node('generate', generate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- 모든 그래프는 `START(시작)`와 `END(종료)`가 있습니다\n",
        "    - `END`를 explicit하게 선언하지 않는 경우도 종종 있지만, 가독성을 위해 작성해주는 것을 권장합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x2a90d3eadb0>"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langgraph.graph import START, END\n",
        "\n",
        "graph_builder.add_edge(START, 'generate')\n",
        "graph_builder.add_edge('generate', END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `node`를 생성하고 `edge`로 연결한 후에 `compile` 메서드를 호출하여 `Graph`를 생성합니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        }
      ],
      "source": [
        "graph = graph_builder.compile()\n",
        "print(type(graph))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- `compile` 후에는 그래프를 시각화하여 확인할 수 있습니다\n",
        "- 의도한대로 그래프가 생성됐는지 확인하는 습관을 기르는 것이 좋습니다\n",
        "    - `git`에서 코드 작업물을 commit하기 전에 `git diff`를 통해 변경사항을 확인하는 것과 같습니다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "#from IPython.display import display, Image\n",
        "\n",
        "#display(Image(graph.get_graph().draw_mermaid_png(max_retries=5, retry_delay=2.0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mermaid Code:\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tgenerate(generate)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> generate;\n",
            "\tgenerate --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 대체 방법\n",
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(\"Mermaid Code:\")\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* https://mermaid.live/ 에서  mermain_code 로 직접 확인한다.\n",
        "\n",
        "* [Graph 이미지](https://mermaidchart.com/play?utm_source=mermaid_live_editor&utm_medium=share#pako:eNpVkN1ugjAUx1-lObvRBLCAVq3Gm_kIu9q6mAqn0AwKKSWZM777KirR3vR8_f7n4wxZkyNwKKxsS_Kx3wgj3OHQOWn9N_natrvR287a3feUc6607dy1sECDVjqcPIzpDUeTj_Bgj2glb-QoSsJwRx745ll0yNz5IZF5uNujIjkq2VeOKF1V_E0liioVVNpgWKIuSsfjKHkBhoGH8rBpZabdidOXgutYd7mjOjKVQeBPonPgzvYYQI22llcXzsIQIsCVWKMA7s1c2h8Bwlw800rz2TT1A7NNX5TAlaw67_Vt7tfaa-mPXY9R6xdE-970xgFP4kED-Bl-gaeURYyyNEmXbJGuaDIP4OTDLIqT-XoVp2tK54ytLwH8DV1ptFou6NOLL_-94J8W) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'dict'>\n",
            "<class 'langchain_core.messages.ai.AIMessage'>\n",
            "[AIMessage(content='**LangGraph**와 **LangChain**은 모두 LLM(Large Language Model)을 활용한 애플리케이션 개발을 위한 프레임워크이지만, 각각 다른 목적과 강점을 가지고 있습니다.  \\n\\n### 1. **LangGraph란?**\\n- **상태(State) 기반의 대화형 LLM 애플리케이션**을 구축하기 위한 프레임워크입니다.  \\n- **그래프 구조**를 사용해 복잡한 대화 흐름(예: 다중 턴 대화, 상태 추적, 조건부 분기)을 모델링할 수 있습니다.  \\n- LangChain과 통합되어 작동하며, 특히 **메모리(Memory) 관리**와 **상태 머신(State Machine) 설계**에 최적화되어 있습니다.  \\n- 예시:  \\n  - 고객 지원 봇 (예: \"주문 확인 → 문제 해결 → 피드백 수집\")  \\n  - 게임형 대화 시스템  \\n  - 복잡한 워크플로우 자동화  \\n\\n### 2. **LangChain과의 차이점**\\n| 특징                | **LangChain**                          | **LangGraph**                          |\\n|---------------------|----------------------------------------|----------------------------------------|\\n| **주요 목적**       | LLM 기반 애플리케이션의 **모듈화** 및 **체인(Chain) 구성** | **상태(State) 관리**와 **대화 흐름 제어** |\\n| **구조**           | 선형/분기형 체인 (Chain, Router 등)    | 그래프 기반 상태 머신 (Node & Edge)    |\\n| **대화 관리**       | 간단한 메모리 기능 지원 (ConversationChain 등) | 복잡한 다중 턴 대화 및 상태 추적 최적화 |\\n| **사용 사례**       | 단일/간단한 LLM 작업 (QA, 요약 등)     | 대화형 에이전트, 워크플로우 자동화      |\\n| **통합 관계**       | LangGraph는 LangChain의 확장 도구      | LangChain 컴포넌트(예: LLM, Memory) 활용 |\\n\\n### 3. **간단한 예시 비교**\\n- **LangChain**:  \\n  ```python\\n  from langchain.chains import LLMChain\\n  from langchain.prompts import PromptTemplate\\n\\n  prompt = PromptTemplate.from_template(\"Tell me a joke about {topic}\")\\n  chain = LLMChain(llm=llm, prompt=prompt)\\n  chain.run(\"cats\")  # \"Why don\\'t cats play poker? Because they\\'re afraid of a cat scan!\"\\n  ```\\n  → 단순한 입력-출력 체인.\\n\\n- **LangGraph**:  \\n  ```python\\n  from langgraph import State, Graph\\n\\n  class MyState(State):\\n      topic: str = \"default\"\\n      jokes: list[str] = []\\n\\n  graph = Graph(MyState)\\n\\n  @graph.node\\n  def ask_topic(state: MyState):\\n      state.topic = llm.predict(\"What\\'s a funny topic?\")\\n      return {\"topic\": state.topic}\\n\\n  @graph.node\\n  def tell_joke(state: MyState):\\n      joke = llm.predict(f\"Tell me a joke about {state.topic}\")\\n      state.jokes.append(joke)\\n      return {}\\n\\n  graph.add_edge(\"ask_topic\", \"tell_joke\")\\n  # 상태 기반으로 흐름 제어 가능\\n  ```\\n  → 상태(`topic`, `jokes`)를 유지하며 대화 흐름을 제어.\\n\\n### 4. **요약**\\n- **LangChain**은 LLM을 활용한 **모듈화된 작업 체인**을 빠르게 구성할 때 유용합니다.  \\n- **LangGraph**는 **상태 추적**과 **복잡한 대화 흐름**이 필요한 애플리케이션에 적합합니다.  \\n- LangGraph는 LangChain의 컴포넌트를 활용하므로, 두 도구를 함께 사용하는 경우가 많습니다.  \\n\\n예를 들어, LangChain으로 간단한 QA 시스템을 만들고, LangGraph로 사용자와의 대화 상태를 관리하며 분기하는 것이 가능합니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 734, 'prompt_tokens': 25, 'total_tokens': 759, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '8171505f-c134-4533-85f4-82bfd02e2452', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--b2c8fff6-186a-41b8-b186-af582a36d3e1-0', usage_metadata={'input_tokens': 25, 'output_tokens': 734, 'total_tokens': 759, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "query = 'LangGraph는 무엇인가요? LangChain과의 차이점은 무엇인가요?'\n",
        "initial_state = {'messages': [HumanMessage(query)]}\n",
        "result = graph.invoke(initial_state)\n",
        "\n",
        "print(type(result))\n",
        "print(type(result['messages'][0]))\n",
        "print(result['messages'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2개의 AI 에이전트 협력하기\n",
        "* 첫번째 AI 에이전트\n",
        "    * 사용자의 질문을 분석하고 핵심 키워드와 배경 정보를 추가하는 역할\n",
        "* 두번째 AI 에이전트\n",
        "    * 첫번째 에이전트가 제공한 정보를 기반으로 좀 더 자세한 답변을 생성하는 역할    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "solar-pro\n"
          ]
        }
      ],
      "source": [
        "print(llm.model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph\n",
        "from pprint import pprint\n",
        "\n",
        "#첫번째 AI 에이전트\n",
        "def agent_1(state):\n",
        "    \"\"\"사용자의 질문을 분석하고 핵심 키워드아 배경 정보를 추가하는 역할\"\"\"\n",
        "    query = state['query']\n",
        "    \n",
        "    keywords = llm.invoke(f'질문: {query}\\n 이 질문에서 핵심 키워드를 3~5개 추출해 주세요.')\n",
        "\n",
        "     # 질문과 관련된 배경 정보 제공\n",
        "    background_info = llm.invoke(f\"질문: {query}\\n 이 질문을 이해하는 데 도움이 될 만한 추가 정보를 제공해 주세요.\")\n",
        "\n",
        "    print(f\"\\n[Agent 1] 원본 질문: {query}\")\n",
        "    print(f\"[Agent 1] 핵심 키워드: {keywords}\")\n",
        "    print(f\"[Agent 1] 배경 정보: {background_info}\\n\")\n",
        "\n",
        "    return {\"refined_query\": query, \"keywords\": keywords, \"background_info\": background_info}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 두번째 AI 에이전트\n",
        "def agent_2(state):\n",
        "    \"\"\"첫번째 에이전트가 제공한 정보를 기반으로 좀 더 자세한 답변을 생성하는 역할\"\"\"\n",
        "    refined_query = state['refined_query']\n",
        "    keywords = state['keywords']\n",
        "    background_info = state['background_info']\n",
        "\n",
        "    # Agent 1이 제공한 정보를 활용하여 최종 답변 생성\n",
        "    final_response = llm.invoke(\n",
        "        f\"질문: {refined_query}\\n\"\n",
        "        f\"핵심 키워드: {keywords}\\n\"\n",
        "        f\"배경 정보: {background_info}\\n\"\n",
        "        f\"위 정보를 바탕으로 질문에 대한 깊이 있는 답변을 작성해 주세요.\"\n",
        "    )\n",
        "\n",
        "    print(f\"[Agent 2] 최종 답변 생성 완료\\n\")\n",
        "    \n",
        "    return {\"final_answer\": final_response}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.StateGraph'>\n",
            "{<class 'dict'>: {'__root__': <langgraph.channels.last_value.LastValue object at 0x000002A90D32E4C0>}}\n"
          ]
        }
      ],
      "source": [
        "# WorkFlow 역할을 하는 StateGraph 객체를 생성하기\n",
        "workflow = StateGraph(dict)\n",
        "\n",
        "print(type(workflow))\n",
        "print(workflow.schemas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'agent_1': StateNodeSpec(runnable=agent_1(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False),\n",
              " 'agent_2': StateNodeSpec(runnable=agent_2(tags=None, recurse=True, explode_args=False, func_accepts={}), metadata=None, input_schema=<class 'dict'>, retry_policy=None, cache_policy=None, ends=(), defer=False)}"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# WorkFlow에 Node 추가하기\n",
        "workflow.add_node(\"agent_1\", agent_1)\n",
        "workflow.add_node(\"agent_2\", agent_2)\n",
        "\n",
        "workflow.nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{('__start__', 'agent_1'), ('agent_1', 'agent_2')}\n"
          ]
        }
      ],
      "source": [
        "# WorkFlow에 Edge 추가하기\n",
        "# agent_1이 먼저 실행됨\n",
        "workflow.set_entry_point(\"agent_1\")\n",
        "# agent_1 -> agent_2\n",
        "workflow.add_edge(\"agent_1\",\"agent_2\")\n",
        "\n",
        "print(workflow.edges)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'langgraph.graph.state.CompiledStateGraph'>\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000002A90D3E8620>"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "graph = workflow.compile()\n",
        "\n",
        "print(type(graph))\n",
        "graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\tagent_1(agent_1)\n",
            "\tagent_2(agent_2)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> agent_1;\n",
            "\tagent_1 --> agent_2;\n",
            "\tagent_2 --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n"
          ]
        }
      ],
      "source": [
        "mermaid_code = graph.get_graph().draw_mermaid()\n",
        "print(mermaid_code)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Agent 1] 원본 질문: LangGraph는 무엇이며, LangChain과 어떤 차이점이 있나요? 그리고 LangGraph를 사용해야 하는 이유는 무엇인가요?\n",
            "[Agent 1] 핵심 키워드: content='핵심 키워드:  \\n1. **LangGraph**  \\n2. **LangChain**  \\n3. **차이점**  \\n4. **사용 이유**  \\n\\n(추가 가능 키워드: **워크플로우 관리**, **상태 기반 대화**)  \\n\\n요약:  \\n- **LangGraph**와 **LangChain**의 관계 및 **차이점**을 묻고, **사용 이유**를 탐구하는 질문입니다.  \\n- LangGraph는 상태(state) 기반의 복잡한 워크플로우 관리에 특화된 도구이며, LangChain은 모듈형 LLM 애플리케이션 구축에 중점을 둡니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 111, 'prompt_tokens': 49, 'total_tokens': 160, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': 'aedd4a38-d00d-46e4-8ae5-8143d1f1b7c0', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--736792c4-3f4d-4204-9435-f9f116a0ee67-0' usage_metadata={'input_tokens': 49, 'output_tokens': 111, 'total_tokens': 160, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "[Agent 1] 배경 정보: content='### **LangGraph란 무엇인가요?**\\nLangGraph는 **LangChain의 확장 프로젝트**로, 복잡한 **상태 기반(stateful) 대화형 애플리케이션**을 구축하기 위한 프레임워크입니다.  \\n- **그래프 기반 워크플로우 관리**에 특화되어 있어, 다중 턴 대화(multi-turn conversation), 상태 추적(state tracking), 조건부 분기(conditional branching)가 필요한 시스템에 적합합니다.  \\n- 예를 들어, 사용자와의 대화가 여러 단계를 거치거나(예: 폼 작성, 결제 프로세스), 이전 대화 기록을 기반으로 다음 액션을 결정해야 하는 경우에 유용합니다.\\n\\n---\\n\\n### **LangChain vs. LangGraph: 주요 차이점**\\n| 특징                | **LangChain**                          | **LangGraph**                          |\\n|---------------------|----------------------------------------|----------------------------------------|\\n| **주요 목적**       | 단일/간단한 체인(chain) 구성           | 복잡한 상태 머신(state machine) 구축    |\\n| **대화 처리**       | 단일 턴 또는 간단한 다단계 대화        | 장기간 유지되는 상태 기반 대화          |\\n| **워크플로우**      | 선형적 또는 분기형 체인                | 그래프 기반 상태 전이(state transitions) |\\n| **상태 관리**       | 제한적 (메모리, 세션 등 외부 의존)     | 내장된 상태 관리 (노드/엣지로 표현)    |\\n| **사용 사례**       | Q&A 챗봇, 문서 요약                   | 예약 시스템, 인터뷰 봇, 복잡한 폼 처리  |\\n\\n> 💡 **예시**:  \\n> - LangChain으로 \"문서에서 답변 추출\" 같은 작업을 쉽게 구현할 수 있지만,  \\n> - LangGraph는 \"사용자가 단계별로 여행 일정을 입력하는 프로세스\"를 관리하는 데 더 적합합니다.\\n\\n---\\n\\n### **LangGraph를 사용해야 하는 이유**\\n1. **복잡한 대화 흐름 관리**  \\n   - 상태(state)를 명시적으로 정의하여 다단계 대화(예: \"주소 입력 → 결제 수단 선택 → 확인\")를 체계적으로 제어할 수 있습니다.  \\n   - 각 단계(노드)와 전이 조건(엣지)을 시각적으로 설계할 수 있습니다.\\n\\n2. **확장성**  \\n   - 그래프 구조로 모듈화가 용이해, 새로운 단계나 조건을 추가하기 쉽습니다.  \\n   - 예: 기존 예약 플로우에 \"할인 쿠폰 적용\" 단계를 추가할 수 있습니다.\\n\\n3. **LangChain과의 통합**  \\n   - LangChain의 컴포넌트(모델, 메모리, 도구)를 LangGraph 노드에 직접 활용할 수 있습니다.  \\n   - 예: `LLMChain`을 LangGraph의 한 노드로 사용해 사용자 입력을 처리합니다.\\n\\n4. **상태 지속성**  \\n   - 세션 간 상태를 그래프에 저장해, 사용자가 중간에 이탈했다가 돌아와도 이전 단계를 이어갈 수 있습니다.\\n\\n5. **시각적 디버깅**  \\n   - 그래프 구조로 워크플로우를 시각화해 논리적 오류를 쉽게 발견할 수 있습니다.\\n\\n---\\n\\n### **추가 정보: LangGraph의 핵심 개념**\\n- **노드(Node)**: 각 대화 단계(예: 사용자 입력 수집, LLM 호출, 데이터베이스 조회).  \\n- **엣지(Edge)**: 상태 전이 조건(예: \"사용자가 \\'예\\'라고 답하면 다음 단계로 이동\").  \\n- **상태(State)**: 대화 중 축적된 정보(예: `{name: \"Alice\", step: 2}`).  \\n- **메모리(Memory)**: LangChain의 메모리를 통합해 과거 컨텍스트를 유지합니다.\\n\\n---\\n\\n### **사용 사례 예시**\\n1. **여행 예약 봇**  \\n   - 단계: 출발지 → 도착지 → 날짜 → 승객 수 → 결제 → 확인.  \\n   - 조건: 날짜가 유효하지 않으면 재입력 요청.\\n\\n2. **의료 증상 체크봇**  \\n   - 증상 기반으로 질문을 동적으로 변경 (예: \"두통이 있나요?\" → \"구토는?\").\\n\\n3. **법적 상담 봇**  \\n   - 사용자 답변에 따라 다른 법률 조항이나 질문을 제시.\\n\\n---\\n\\n### **시작하는 방법**\\n1. 설치:  \\n   ```bash\\n   pip install langgraph\\n   ```\\n2. 기본 예제 (LangChain + LangGraph 통합):  \\n   ```python\\n   from langgraph import State, BaseNode\\n   from langchain_core.prompts import ChatPromptTemplate\\n   from langchain_openai import ChatOpenAI\\n\\n   class LLMNode(BaseNode):\\n       def __init__(self):\\n           self.prompt = ChatPromptTemplate.from_template(\"답변: {input}\")\\n           self.llm = ChatOpenAI()\\n\\n       def run(self, state: State, inputs: dict) -> dict:\\n           response = self.llm.invoke(self.prompt.format_messages(input=inputs[\"input\"]))\\n           state[\"response\"] = response.content\\n           return {}\\n\\n   # 그래프 정의 및 실행 로직은 공식 문서 참조\\n   ```\\n\\nLangGraph는 **복잡한 대화 시스템을 체계적으로 설계**할 때 특히 강력하며, LangChain의 유연성과 결합해 AI 애플리케이션 개발의 새로운 가능성을 열어줍니다. 🚀' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 942, 'prompt_tokens': 49, 'total_tokens': 991, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '1d0a5b9d-5315-40f8-a989-4657503c18b7', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None} id='run--0ad4a29e-d2fe-4a83-94d9-b60a8bdaa707-0' usage_metadata={'input_tokens': 49, 'output_tokens': 942, 'total_tokens': 991, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
            "\n",
            "[Agent 2] 최종 답변 생성 완료\n",
            "\n",
            "{'final_answer': AIMessage(content='### **LangGraph vs. LangChain: 핵심 차이점과 사용 이유**\\n\\n#### 1. **LangGraph란?**  \\nLangGraph는 **LangChain의 확장 프레임워크**로, **상태(state) 기반의 복잡한 워크플로우 관리**에 특화된 도구입니다.  \\n- **그래프 기반 아키텍처**를 사용해 다단계 대화, 조건부 분기, 상태 추적이 필요한 시스템을 구축합니다.  \\n- 예시: 여행 예약 봇, 의료 증상 체크봇, 법적 상담 봇과 같이 **사용자 입력에 따라 동적으로 흐름이 변경되는 애플리케이션**에 적합합니다.  \\n\\n#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n| **기준**               | **LangChain**                          | **LangGraph**                          |\\n|------------------------|----------------------------------------|----------------------------------------|\\n| **주요 목적**          | 단일/간단한 체인(Chain) 구성          | 복잡한 상태 머신(State Machine) 구축   |\\n| **대화 처리**          | 단일 턴 또는 선형적 다단계 대화        | 장기간 상태 유지 및 동적 분기          |\\n| **워크플로우 구조**    | 선형적 또는 분기형 체인                | 그래프 기반 상태 전이 (노드/엣지)      |\\n| **상태 관리**          | 외부 메모리(예: `ConversationBufferMemory`) 의존 | 내장된 상태 객체(`State`)로 명시적 관리 |\\n| **사용 사례**          | Q&A 챗봇, 문서 요약                   | 예약 시스템, 폼 처리, 인터뷰 봇        |\\n\\n> 💡 **차이점 요약**:  \\n> - LangChain은 **\"단순한 작업 체인\"**에 강점이 있고,  \\n> - LangGraph는 **\"복잡한 상태 전이\"**가 필요한 워크플로우를 체계적으로 설계합니다.\\n\\n#### 3. **LangGraph를 사용해야 하는 이유**  \\n**(1) 복잡한 대화 흐름 관리**  \\n- **상태(state)**를 명시적으로 정의해 다단계 대화를 제어합니다.  \\n  - 예: `{step: \"결제\", user_data: {...}}`와 같은 상태 객체로 현재 단계와 데이터를 추적합니다.  \\n- **조건부 분기**를 엣지(Edge)로 표현해, 사용자 입력에 따라 다음 단계를 동적으로 결정합니다.  \\n  - 예: \"사용자가 \\'예\\'라고 답하면 다음 단계로 이동\"하는 조건을 코드로 구현합니다.  \\n\\n**(2) 확장성**  \\n- 그래프 구조로 모듈화가 용이합니다.  \\n  - 새로운 단계(노드)나 조건(엣지)을 추가할 때 기존 로직을 수정하지 않아도 됩니다.  \\n  - 예: 기존 예약 플로우에 \"할인 쿠폰 적용\" 단계를 추가할 수 있습니다.  \\n\\n**(3) LangChain과의 원활한 통합**  \\n- LangChain의 컴포넌트(예: `LLMChain`, `Tools`)를 LangGraph 노드로 직접 활용할 수 있습니다.  \\n  - 예: `LLMNode` 클래스로 LLM 호출을 구현하고, 이를 그래프의 한 단계로 통합합니다.  \\n\\n**(4) 상태 지속성**  \\n- 세션 간 상태를 저장해 사용자가 중간에 이탈해도 이전 단계를 이어갈 수 있습니다.  \\n  - 예: 웹 애플리케이션에서 사용자가 페이지를 나갔다가 돌아와도 폼 작성이 유지됩니다.  \\n\\n**(5) 시각적 디버깅**  \\n- 그래프 구조로 워크플로우를 시각화해 논리적 오류를 쉽게 발견할 수 있습니다.  \\n  - LangGraph의 `draw` 함수로 그래프를 시각화할 수 있습니다.  \\n\\n#### 4. **핵심 개념**  \\n- **노드(Node)**: 각 대화 단계 (예: 사용자 입력 수집, LLM 호출, DB 조회).  \\n- **엣지(Edge)**: 상태 전이 조건 (예: \"답변이 \\'A\\'이면 다음 노드로 이동\").  \\n- **상태(State)**: 대화 중 축적된 정보 (예: `{name: \"Alice\", step: 2}`).  \\n- **메모리(Memory)**: LangChain의 메모리를 통합해 과거 컨텍스트를 유지합니다.  \\n\\n#### 5. **사용 사례 예시**  \\n1. **여행 예약 봇**  \\n   - 단계: 출발지 → 도착지 → 날짜 → 승객 수 → 결제 → 확인.  \\n   - 조건: 날짜가 유효하지 않으면 재입력 요청.  \\n2. **의료 증상 체크봇**  \\n   - 증상 기반으로 질문을 동적으로 변경 (예: \"두통이 있나요?\" → \"구토는?\").  \\n3. **법적 상담 봇**  \\n   - 사용자 답변에 따라 다른 법률 조항이나 질문을 제시.  \\n\\n#### 6. **시작하는 방법**  \\n```bash\\npip install langgraph\\n```\\n```python\\nfrom langgraph import State, BaseNode\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\nclass LLMNode(BaseNode):\\n    def __init__(self):\\n        self.prompt = ChatPromptTemplate.from_template(\"답변: {input}\")\\n        self.llm = ChatOpenAI()\\n\\n    def run(self, state: State, inputs: dict) -> dict:\\n        response = self.llm.invoke(self.prompt.format_messages(input=inputs[\"input\"]))\\n        state[\"response\"] = response.content  # 상태 업데이트\\n        return {}  # 다음 노드로 전달할 데이터 (없음)\\n\\n# 그래프 정의 (공식 문서 참조)\\n```\\n\\n### **결론: LangGraph를 선택해야 하는 경우**  \\n- **다단계 상태 기반 대화**가 필요할 때 (예: 폼 처리, 예약 시스템).  \\n- **조건부 분기**와 **동적 워크플로우**가 필요한 복잡한 애플리케이션.  \\n- LangChain의 유연성과 결합해 **확장성**이 필요한 프로젝트.  \\n\\nLangGraph는 **\"복잡한 대화 시스템을 체계적으로 설계\"**할 때 LangChain보다 더 강력한 도구입니다. 🚀', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1109, 'prompt_tokens': 1830, 'total_tokens': 2939, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '8ba01f11-e822-4d61-ba50-8713ef7cf7a1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5d74413d-054c-4637-a854-ca2bda445f45-0', usage_metadata={'input_tokens': 1830, 'output_tokens': 1109, 'total_tokens': 2939, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
          ]
        }
      ],
      "source": [
        "# Graph 호출하기\n",
        "query = \"LangGraph는 무엇이며, LangChain과 어떤 차이점이 있나요? 그리고 LangGraph를 사용해야 하는 이유는 무엇인가요?\"\n",
        "\n",
        "state = {\"query\": query}\n",
        "result = graph.invoke(state)\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'final_answer': AIMessage(content='### **LangGraph vs. LangChain: 핵심 차이점과 사용 이유**\\n\\n#### 1. **LangGraph란?**  \\nLangGraph는 **LangChain의 확장 프레임워크**로, **상태(state) 기반의 복잡한 워크플로우 관리**에 특화된 도구입니다.  \\n- **그래프 기반 아키텍처**를 사용해 다단계 대화, 조건부 분기, 상태 추적이 필요한 시스템을 구축합니다.  \\n- 예시: 여행 예약 봇, 의료 증상 체크봇, 법적 상담 봇과 같이 **사용자 입력에 따라 동적으로 흐름이 변경되는 애플리케이션**에 적합합니다.  \\n\\n#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n| **기준**               | **LangChain**                          | **LangGraph**                          |\\n|------------------------|----------------------------------------|----------------------------------------|\\n| **주요 목적**          | 단일/간단한 체인(Chain) 구성          | 복잡한 상태 머신(State Machine) 구축   |\\n| **대화 처리**          | 단일 턴 또는 선형적 다단계 대화        | 장기간 상태 유지 및 동적 분기          |\\n| **워크플로우 구조**    | 선형적 또는 분기형 체인                | 그래프 기반 상태 전이 (노드/엣지)      |\\n| **상태 관리**          | 외부 메모리(예: `ConversationBufferMemory`) 의존 | 내장된 상태 객체(`State`)로 명시적 관리 |\\n| **사용 사례**          | Q&A 챗봇, 문서 요약                   | 예약 시스템, 폼 처리, 인터뷰 봇        |\\n\\n> 💡 **차이점 요약**:  \\n> - LangChain은 **\"단순한 작업 체인\"**에 강점이 있고,  \\n> - LangGraph는 **\"복잡한 상태 전이\"**가 필요한 워크플로우를 체계적으로 설계합니다.\\n\\n#### 3. **LangGraph를 사용해야 하는 이유**  \\n**(1) 복잡한 대화 흐름 관리**  \\n- **상태(state)**를 명시적으로 정의해 다단계 대화를 제어합니다.  \\n  - 예: `{step: \"결제\", user_data: {...}}`와 같은 상태 객체로 현재 단계와 데이터를 추적합니다.  \\n- **조건부 분기**를 엣지(Edge)로 표현해, 사용자 입력에 따라 다음 단계를 동적으로 결정합니다.  \\n  - 예: \"사용자가 \\'예\\'라고 답하면 다음 단계로 이동\"하는 조건을 코드로 구현합니다.  \\n\\n**(2) 확장성**  \\n- 그래프 구조로 모듈화가 용이합니다.  \\n  - 새로운 단계(노드)나 조건(엣지)을 추가할 때 기존 로직을 수정하지 않아도 됩니다.  \\n  - 예: 기존 예약 플로우에 \"할인 쿠폰 적용\" 단계를 추가할 수 있습니다.  \\n\\n**(3) LangChain과의 원활한 통합**  \\n- LangChain의 컴포넌트(예: `LLMChain`, `Tools`)를 LangGraph 노드로 직접 활용할 수 있습니다.  \\n  - 예: `LLMNode` 클래스로 LLM 호출을 구현하고, 이를 그래프의 한 단계로 통합합니다.  \\n\\n**(4) 상태 지속성**  \\n- 세션 간 상태를 저장해 사용자가 중간에 이탈해도 이전 단계를 이어갈 수 있습니다.  \\n  - 예: 웹 애플리케이션에서 사용자가 페이지를 나갔다가 돌아와도 폼 작성이 유지됩니다.  \\n\\n**(5) 시각적 디버깅**  \\n- 그래프 구조로 워크플로우를 시각화해 논리적 오류를 쉽게 발견할 수 있습니다.  \\n  - LangGraph의 `draw` 함수로 그래프를 시각화할 수 있습니다.  \\n\\n#### 4. **핵심 개념**  \\n- **노드(Node)**: 각 대화 단계 (예: 사용자 입력 수집, LLM 호출, DB 조회).  \\n- **엣지(Edge)**: 상태 전이 조건 (예: \"답변이 \\'A\\'이면 다음 노드로 이동\").  \\n- **상태(State)**: 대화 중 축적된 정보 (예: `{name: \"Alice\", step: 2}`).  \\n- **메모리(Memory)**: LangChain의 메모리를 통합해 과거 컨텍스트를 유지합니다.  \\n\\n#### 5. **사용 사례 예시**  \\n1. **여행 예약 봇**  \\n   - 단계: 출발지 → 도착지 → 날짜 → 승객 수 → 결제 → 확인.  \\n   - 조건: 날짜가 유효하지 않으면 재입력 요청.  \\n2. **의료 증상 체크봇**  \\n   - 증상 기반으로 질문을 동적으로 변경 (예: \"두통이 있나요?\" → \"구토는?\").  \\n3. **법적 상담 봇**  \\n   - 사용자 답변에 따라 다른 법률 조항이나 질문을 제시.  \\n\\n#### 6. **시작하는 방법**  \\n```bash\\npip install langgraph\\n```\\n```python\\nfrom langgraph import State, BaseNode\\nfrom langchain_core.prompts import ChatPromptTemplate\\nfrom langchain_openai import ChatOpenAI\\n\\nclass LLMNode(BaseNode):\\n    def __init__(self):\\n        self.prompt = ChatPromptTemplate.from_template(\"답변: {input}\")\\n        self.llm = ChatOpenAI()\\n\\n    def run(self, state: State, inputs: dict) -> dict:\\n        response = self.llm.invoke(self.prompt.format_messages(input=inputs[\"input\"]))\\n        state[\"response\"] = response.content  # 상태 업데이트\\n        return {}  # 다음 노드로 전달할 데이터 (없음)\\n\\n# 그래프 정의 (공식 문서 참조)\\n```\\n\\n### **결론: LangGraph를 선택해야 하는 경우**  \\n- **다단계 상태 기반 대화**가 필요할 때 (예: 폼 처리, 예약 시스템).  \\n- **조건부 분기**와 **동적 워크플로우**가 필요한 복잡한 애플리케이션.  \\n- LangChain의 유연성과 결합해 **확장성**이 필요한 프로젝트.  \\n\\nLangGraph는 **\"복잡한 대화 시스템을 체계적으로 설계\"**할 때 LangChain보다 더 강력한 도구입니다. 🚀', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 1109, 'prompt_tokens': 1830, 'total_tokens': 2939, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'solar-pro2-250909', 'system_fingerprint': None, 'id': '8ba01f11-e822-4d61-ba50-8713ef7cf7a1', 'service_tier': None, 'finish_reason': 'stop', 'logprobs': None}, id='run--5d74413d-054c-4637-a854-ca2bda445f45-0', usage_metadata={'input_tokens': 1830, 'output_tokens': 1109, 'total_tokens': 2939, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})}\n"
          ]
        }
      ],
      "source": [
        "pprint(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('### **LangGraph vs. LangChain: 핵심 차이점과 사용 이유**\\n'\n",
            " '\\n'\n",
            " '#### 1. **LangGraph란?**  \\n'\n",
            " 'LangGraph는 **LangChain의 확장 프레임워크**로, **상태(state) 기반의 복잡한 워크플로우 관리**에 특화된 '\n",
            " '도구입니다.  \\n'\n",
            " '- **그래프 기반 아키텍처**를 사용해 다단계 대화, 조건부 분기, 상태 추적이 필요한 시스템을 구축합니다.  \\n'\n",
            " '- 예시: 여행 예약 봇, 의료 증상 체크봇, 법적 상담 봇과 같이 **사용자 입력에 따라 동적으로 흐름이 변경되는 애플리케이션**에 '\n",
            " '적합합니다.  \\n'\n",
            " '\\n'\n",
            " '#### 2. **LangChain vs. LangGraph: 주요 차이점**  \\n'\n",
            " '| **기준**               | **LangChain**                          | '\n",
            " '**LangGraph**                          |\\n'\n",
            " '|------------------------|----------------------------------------|----------------------------------------|\\n'\n",
            " '| **주요 목적**          | 단일/간단한 체인(Chain) 구성          | 복잡한 상태 머신(State '\n",
            " 'Machine) 구축   |\\n'\n",
            " '| **대화 처리**          | 단일 턴 또는 선형적 다단계 대화        | 장기간 상태 유지 및 동적 '\n",
            " '분기          |\\n'\n",
            " '| **워크플로우 구조**    | 선형적 또는 분기형 체인                | 그래프 기반 상태 전이 (노드/엣지)      '\n",
            " '|\\n'\n",
            " '| **상태 관리**          | 외부 메모리(예: `ConversationBufferMemory`) 의존 | 내장된 상태 '\n",
            " '객체(`State`)로 명시적 관리 |\\n'\n",
            " '| **사용 사례**          | Q&A 챗봇, 문서 요약                   | 예약 시스템, 폼 처리, 인터뷰 '\n",
            " '봇        |\\n'\n",
            " '\\n'\n",
            " '> 💡 **차이점 요약**:  \\n'\n",
            " '> - LangChain은 **\"단순한 작업 체인\"**에 강점이 있고,  \\n'\n",
            " '> - LangGraph는 **\"복잡한 상태 전이\"**가 필요한 워크플로우를 체계적으로 설계합니다.\\n'\n",
            " '\\n'\n",
            " '#### 3. **LangGraph를 사용해야 하는 이유**  \\n'\n",
            " '**(1) 복잡한 대화 흐름 관리**  \\n'\n",
            " '- **상태(state)**를 명시적으로 정의해 다단계 대화를 제어합니다.  \\n'\n",
            " '  - 예: `{step: \"결제\", user_data: {...}}`와 같은 상태 객체로 현재 단계와 데이터를 추적합니다.  \\n'\n",
            " '- **조건부 분기**를 엣지(Edge)로 표현해, 사용자 입력에 따라 다음 단계를 동적으로 결정합니다.  \\n'\n",
            " '  - 예: \"사용자가 \\'예\\'라고 답하면 다음 단계로 이동\"하는 조건을 코드로 구현합니다.  \\n'\n",
            " '\\n'\n",
            " '**(2) 확장성**  \\n'\n",
            " '- 그래프 구조로 모듈화가 용이합니다.  \\n'\n",
            " '  - 새로운 단계(노드)나 조건(엣지)을 추가할 때 기존 로직을 수정하지 않아도 됩니다.  \\n'\n",
            " '  - 예: 기존 예약 플로우에 \"할인 쿠폰 적용\" 단계를 추가할 수 있습니다.  \\n'\n",
            " '\\n'\n",
            " '**(3) LangChain과의 원활한 통합**  \\n'\n",
            " '- LangChain의 컴포넌트(예: `LLMChain`, `Tools`)를 LangGraph 노드로 직접 활용할 수 있습니다.  \\n'\n",
            " '  - 예: `LLMNode` 클래스로 LLM 호출을 구현하고, 이를 그래프의 한 단계로 통합합니다.  \\n'\n",
            " '\\n'\n",
            " '**(4) 상태 지속성**  \\n'\n",
            " '- 세션 간 상태를 저장해 사용자가 중간에 이탈해도 이전 단계를 이어갈 수 있습니다.  \\n'\n",
            " '  - 예: 웹 애플리케이션에서 사용자가 페이지를 나갔다가 돌아와도 폼 작성이 유지됩니다.  \\n'\n",
            " '\\n'\n",
            " '**(5) 시각적 디버깅**  \\n'\n",
            " '- 그래프 구조로 워크플로우를 시각화해 논리적 오류를 쉽게 발견할 수 있습니다.  \\n'\n",
            " '  - LangGraph의 `draw` 함수로 그래프를 시각화할 수 있습니다.  \\n'\n",
            " '\\n'\n",
            " '#### 4. **핵심 개념**  \\n'\n",
            " '- **노드(Node)**: 각 대화 단계 (예: 사용자 입력 수집, LLM 호출, DB 조회).  \\n'\n",
            " '- **엣지(Edge)**: 상태 전이 조건 (예: \"답변이 \\'A\\'이면 다음 노드로 이동\").  \\n'\n",
            " '- **상태(State)**: 대화 중 축적된 정보 (예: `{name: \"Alice\", step: 2}`).  \\n'\n",
            " '- **메모리(Memory)**: LangChain의 메모리를 통합해 과거 컨텍스트를 유지합니다.  \\n'\n",
            " '\\n'\n",
            " '#### 5. **사용 사례 예시**  \\n'\n",
            " '1. **여행 예약 봇**  \\n'\n",
            " '   - 단계: 출발지 → 도착지 → 날짜 → 승객 수 → 결제 → 확인.  \\n'\n",
            " '   - 조건: 날짜가 유효하지 않으면 재입력 요청.  \\n'\n",
            " '2. **의료 증상 체크봇**  \\n'\n",
            " '   - 증상 기반으로 질문을 동적으로 변경 (예: \"두통이 있나요?\" → \"구토는?\").  \\n'\n",
            " '3. **법적 상담 봇**  \\n'\n",
            " '   - 사용자 답변에 따라 다른 법률 조항이나 질문을 제시.  \\n'\n",
            " '\\n'\n",
            " '#### 6. **시작하는 방법**  \\n'\n",
            " '```bash\\n'\n",
            " 'pip install langgraph\\n'\n",
            " '```\\n'\n",
            " '```python\\n'\n",
            " 'from langgraph import State, BaseNode\\n'\n",
            " 'from langchain_core.prompts import ChatPromptTemplate\\n'\n",
            " 'from langchain_openai import ChatOpenAI\\n'\n",
            " '\\n'\n",
            " 'class LLMNode(BaseNode):\\n'\n",
            " '    def __init__(self):\\n'\n",
            " '        self.prompt = ChatPromptTemplate.from_template(\"답변: {input}\")\\n'\n",
            " '        self.llm = ChatOpenAI()\\n'\n",
            " '\\n'\n",
            " '    def run(self, state: State, inputs: dict) -> dict:\\n'\n",
            " '        response = '\n",
            " 'self.llm.invoke(self.prompt.format_messages(input=inputs[\"input\"]))\\n'\n",
            " '        state[\"response\"] = response.content  # 상태 업데이트\\n'\n",
            " '        return {}  # 다음 노드로 전달할 데이터 (없음)\\n'\n",
            " '\\n'\n",
            " '# 그래프 정의 (공식 문서 참조)\\n'\n",
            " '```\\n'\n",
            " '\\n'\n",
            " '### **결론: LangGraph를 선택해야 하는 경우**  \\n'\n",
            " '- **다단계 상태 기반 대화**가 필요할 때 (예: 폼 처리, 예약 시스템).  \\n'\n",
            " '- **조건부 분기**와 **동적 워크플로우**가 필요한 복잡한 애플리케이션.  \\n'\n",
            " '- LangChain의 유연성과 결합해 **확장성**이 필요한 프로젝트.  \\n'\n",
            " '\\n'\n",
            " 'LangGraph는 **\"복잡한 대화 시스템을 체계적으로 설계\"**할 때 LangChain보다 더 강력한 도구입니다. 🚀')\n"
          ]
        }
      ],
      "source": [
        "\n",
        "pprint(result['final_answer'].content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "mylangchain-app-SBe-Yh6W-py3.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
